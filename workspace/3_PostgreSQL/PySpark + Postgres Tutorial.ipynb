{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215cc350",
   "metadata": {},
   "source": [
    "# Accessing PostgreSQL with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410adf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6f7d1c72b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c118760a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.eventLog.dir', 'hdfs://master:9000/spark-logs'),\n",
       " ('spark.sql.repl.eagerEval.enabled', 'true'),\n",
       " ('spark.driver.port', '34231'),\n",
       " ('spark.jars',\n",
       "  'file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.master', 'spark://master:7077'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,/root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,/root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,/root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.history.fs.logDirectory', 'hdfs://master:9000/spark-logs'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.app.startTime', '1647155840182'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://master:34231/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,spark://master:34231/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,spark://master:34231/jars/org.mongodb_bson-4.0.5.jar,spark://master:34231/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.history.provider',\n",
       "  'org.apache.spark.deploy.history.FsHistoryProvider'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.history.fs.update.interval', '10s'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.extraJavaOptions', '-Dderby.system.home=/tmp/derby/'),\n",
       " ('spark.yarn.historyServer.address', 'master:18080'),\n",
       " ('spark.app.id', 'app-20220313071723-0013'),\n",
       " ('spark.app.initial.file.urls',\n",
       "  'spark://master:34231/files/org.mongodb_bson-4.0.5.jar,spark://master:34231/files/org.mongodb_mongodb-driver-core-4.0.5.jar,spark://master:34231/files/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,spark://master:34231/files/org.mongodb_mongodb-driver-sync-4.0.5.jar'),\n",
       " ('spark.history.ui.port', '18080'),\n",
       " ('spark.driver.host', 'master'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.sql.warehouse.dir', 'hdfs://master:9000/apps/hive/warehouse'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.files',\n",
       "  'file:///root/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_bson-4.0.5.jar,file:///root/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar'),\n",
       " ('spark.yarn.jars', 'hdfs:///spark-jars/*.jar'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.cores', '1'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72332d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/3_PostgreSQL\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a27f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1388\r\n",
      "drwxr-xr-x. 3 root root     183 Mar 13 07:16  .\r\n",
      "drwxr-xr-x. 9 root root     134 Mar 13 01:08  ..\r\n",
      "drwxr-xr-x. 2 root root      58 Mar 10 12:54  .ipynb_checkpoints\r\n",
      "-rw-r--r--. 1 root root   20738 Mar 13 07:16 'PySpark + Postgres Tutorial.ipynb'\r\n",
      "-rw-r--r--. 1 root root 1039047 Mar  8 09:18  postgresql-42.3.3.jar\r\n",
      "-rw-r--r--. 1 root root   84199 Mar 13 05:26  winequality-red.csv\r\n",
      "-rw-r--r--. 1 root root  264426 Mar 13 05:26  winequality-white.csv\r\n",
      "-rw-r--r--. 1 root root    3305 Mar 13 05:26  winequality.names\r\n"
     ]
    }
   ],
   "source": [
    "! ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f71afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = 'postgres'\n",
    "port = 5432\n",
    "user = \"postgres\"\n",
    "passwd = \"go2team\"\n",
    "db = \"empdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94dda4",
   "metadata": {},
   "source": [
    "# Write data into Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5983b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "studentDf = spark.createDataFrame([\n",
    "    Row(id=1,name='vijay',marks=67),\n",
    "    Row(id=2,name='Ajay',marks=88),\n",
    "    Row(id=3,name='jay',marks=79),\n",
    "    Row(id=4,name='vinay',marks=67),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3328d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| name|marks|\n",
      "+---+-----+-----+\n",
      "|  1|vijay|   67|\n",
      "|  2| Ajay|   88|\n",
      "|  3|  jay|   79|\n",
      "|  4|vinay|   67|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "studentDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78842e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "studentDf.select(\"id\",\"name\",\"marks\").write.format(\"jdbc\")\\\n",
    "    .option(\"url\",\"jdbc:postgresql://{0}:{1}/{2}\".format( ip, port, db ))\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "    .option(\"dbtable\", \"students\")\\\n",
    "    .option(\"user\", user ).option(\"password\", passwd ).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede430cf",
   "metadata": {},
   "source": [
    "## Read table from empdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05fc1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select * from students\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04215988",
   "metadata": {},
   "outputs": [],
   "source": [
    "postgreTable = spark.read.format(\"jdbc\")\\\n",
    "                    .option(\"url\",\"jdbc:postgresql://{0}:{1}/{2}\".format( ip, port, db ))\\\n",
    "                    .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "                    .option(\"query\", sql).option(\"user\", user).option(\"password\", passwd).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca90b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| name|marks|\n",
      "+---+-----+-----+\n",
      "|  1|vijay|   67|\n",
      "|  2| Ajay|   88|\n",
      "|  3|  jay|   79|\n",
      "|  4|vinay|   67|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "postgreTable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2aac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
